{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_QA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2HAsSBR6GGcvkHUoXHGZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e520db6e8a234f86b144b8da08d5c26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce30b2c9b2564945ac169b4185110246",
              "IPY_MODEL_5a53417311fb4c3f9a4bb7544c3b698f",
              "IPY_MODEL_15616279df694f5382b6ca3f439eb89a"
            ],
            "layout": "IPY_MODEL_ad769e7fe18c454888ae2d32642855f0"
          }
        },
        "ce30b2c9b2564945ac169b4185110246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f9a2608d014cf684f0a5d04240b012",
            "placeholder": "​",
            "style": "IPY_MODEL_cb21ee33d5b64b00b0debc088cd539db",
            "value": "100%"
          }
        },
        "5a53417311fb4c3f9a4bb7544c3b698f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4936654ebf734681aae9f25ed8855032",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f375ca71d7643c8b9226e62333fee27",
            "value": 2
          }
        },
        "15616279df694f5382b6ca3f439eb89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d66124e1e644dce9b1a2b6210b0f12a",
            "placeholder": "​",
            "style": "IPY_MODEL_648616fb71cb4892a5e658db5ac56140",
            "value": " 2/2 [00:00&lt;00:00, 50.21it/s]"
          }
        },
        "ad769e7fe18c454888ae2d32642855f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f9a2608d014cf684f0a5d04240b012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb21ee33d5b64b00b0debc088cd539db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4936654ebf734681aae9f25ed8855032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f375ca71d7643c8b9226e62333fee27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d66124e1e644dce9b1a2b6210b0f12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "648616fb71cb4892a5e658db5ac56140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e74cfe8889c048cb998c2779a4b19a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_941601b03459471abebd1774e31adab7",
              "IPY_MODEL_02aa9c296c834525942a68c7137e2720",
              "IPY_MODEL_7c9961538b0d4c4d9e6d63cb3171891d"
            ],
            "layout": "IPY_MODEL_b9a140e440db495889d883d2375d7ea9"
          }
        },
        "941601b03459471abebd1774e31adab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370678d5bc464f089738c19adc8383b5",
            "placeholder": "​",
            "style": "IPY_MODEL_d8fecbd0b1964050bb60a660ac6cabde",
            "value": "100%"
          }
        },
        "02aa9c296c834525942a68c7137e2720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd497005ea541599b1b99e355c70f81",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddf68994cd9c4e11b4e1ad62138842f1",
            "value": 88
          }
        },
        "7c9961538b0d4c4d9e6d63cb3171891d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e73162cbe6c4f079ccb18955d81d62a",
            "placeholder": "​",
            "style": "IPY_MODEL_789df237fba64096885fa87b6f38b1c4",
            "value": " 88/88 [00:51&lt;00:00,  1.87ba/s]"
          }
        },
        "b9a140e440db495889d883d2375d7ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370678d5bc464f089738c19adc8383b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8fecbd0b1964050bb60a660ac6cabde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd497005ea541599b1b99e355c70f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf68994cd9c4e11b4e1ad62138842f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e73162cbe6c4f079ccb18955d81d62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789df237fba64096885fa87b6f38b1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a14faa044824a00b2486cef01995c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06e8ef7825db4a699428555df67f97d0",
              "IPY_MODEL_bdc45207350945b39e319c23066222c8",
              "IPY_MODEL_fca50d376a194e9d96e37a7ec07911bb"
            ],
            "layout": "IPY_MODEL_a92f30c853e24c9db920d9d2d8e160f2"
          }
        },
        "06e8ef7825db4a699428555df67f97d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc8fb17789c4b839cc29494b0eb0881",
            "placeholder": "​",
            "style": "IPY_MODEL_b412cd1c43694f2db5a47f3b2b453b93",
            "value": "100%"
          }
        },
        "bdc45207350945b39e319c23066222c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6367cbe64f2642b7993b03d408f47678",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20e86cfa162a4cbf8e768fd8167a078b",
            "value": 11
          }
        },
        "fca50d376a194e9d96e37a7ec07911bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879130c176664f798981030916edf4fc",
            "placeholder": "​",
            "style": "IPY_MODEL_1498fb2c370141619d84b06bea0c4129",
            "value": " 11/11 [00:06&lt;00:00,  1.88ba/s]"
          }
        },
        "a92f30c853e24c9db920d9d2d8e160f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc8fb17789c4b839cc29494b0eb0881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b412cd1c43694f2db5a47f3b2b453b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6367cbe64f2642b7993b03d408f47678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e86cfa162a4cbf8e768fd8167a078b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "879130c176664f798981030916edf4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1498fb2c370141619d84b06bea0c4129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cabec635c33e4392b448fcf3dd39c9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52be18c9efa04d4582fc3d316bc9a231",
              "IPY_MODEL_cae397f4ff214cb9aa7ce1909023fbca",
              "IPY_MODEL_c9817373e6bc49298ca5eb2afccbb921"
            ],
            "layout": "IPY_MODEL_e42f49487a42481b9e964d5c894d6975"
          }
        },
        "52be18c9efa04d4582fc3d316bc9a231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e93ad4f5cb49a3959503dced9b0bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_c3429c05b1734841b1fba76f32fa1706",
            "value": "100%"
          }
        },
        "cae397f4ff214cb9aa7ce1909023fbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818c8ff6e22c4f9489bcd8020bbf55e7",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0d432944b3e40728af5cd01ecd4dcff",
            "value": 11
          }
        },
        "c9817373e6bc49298ca5eb2afccbb921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8588bbff508c41c09926ebf0cfd6ce2f",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3fafd0dee74a76a82a4d59dcabbd22",
            "value": " 11/11 [01:03&lt;00:00,  5.16s/ba]"
          }
        },
        "e42f49487a42481b9e964d5c894d6975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e93ad4f5cb49a3959503dced9b0bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3429c05b1734841b1fba76f32fa1706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818c8ff6e22c4f9489bcd8020bbf55e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d432944b3e40728af5cd01ecd4dcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8588bbff508c41c09926ebf0cfd6ce2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3fafd0dee74a76a82a4d59dcabbd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/QA_tutorial/blob/main/transformers_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QA with transformers\n",
        "\n",
        "transformers document教程中的例子\n",
        "\n",
        "*    dataset squad\n",
        "*    model  distilbert-base-uncased\n",
        "*    metric"
      ],
      "metadata": {
        "id": "QgXd1c7bwzl6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SNgzqEHEwsiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75aa4379-34b3-4e45-dda5-887a830dfdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 163 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 57.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 17.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#参数设置\n",
        "\n",
        "model_checkpoint='distilbert-base-uncased'\n",
        "batch_size=16\n",
        "squad_v2=False"
      ],
      "metadata": {
        "id": "1jwnxl3uyQBu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##加载数据"
      ],
      "metadata": {
        "id": "IXTXJZDSyZ_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset,load_metric\n",
        "from datasets import ClassLabel,Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display ,HTML\n",
        "\n",
        "datasets=load_dataset('squad')\n",
        "\n",
        "def show_random_elements(dataset,num_examples=10):\n",
        "  assert num_examples<=len(dataset)\n",
        "  picks=[]\n",
        "  for _ in range(num_examples):\n",
        "    pick=random.randint(0,len(dataset)-1)\n",
        "    while pick in picks:\n",
        "      pick=random.randint(0,len(dataset)-1)\n",
        "    picks.append(pick)\n",
        "  df=pd.DataFrame(dataset[picks])\n",
        "  for column,typ in dataset.features.items():\n",
        "    if isinstance(typ,ClassLabel):\n",
        "      df[column]=df[column].transform(lambda i:typ.names[i])\n",
        "    elif isinstance(typ,Sequence) and isinstance(typ.feature,ClassLabel):\n",
        "      df[column]=df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "  display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(datasets[\"train\"])"
      ],
      "metadata": {
        "id": "Au-AGQmfyNTC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e520db6e8a234f86b144b8da08d5c26c",
            "ce30b2c9b2564945ac169b4185110246",
            "5a53417311fb4c3f9a4bb7544c3b698f",
            "15616279df694f5382b6ca3f439eb89a",
            "ad769e7fe18c454888ae2d32642855f0",
            "11f9a2608d014cf684f0a5d04240b012",
            "cb21ee33d5b64b00b0debc088cd539db",
            "4936654ebf734681aae9f25ed8855032",
            "7f375ca71d7643c8b9226e62333fee27",
            "7d66124e1e644dce9b1a2b6210b0f12a",
            "648616fb71cb4892a5e658db5ac56140"
          ]
        },
        "outputId": "2187daca-772e-4788-f8b0-db4d97759a37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e520db6e8a234f86b144b8da08d5c26c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>572a7e1abe1ee31400cb8037</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Miami is also considered a \"hot spot\" for dance music, Freestyle, a style of dance music popular in the 80's and 90's heavily influenced by Electro, hip-hop, and disco. Many popular Freestyle acts such as Pretty Tony, Debbie Deb, Stevie B, and Exposé, originated in Miami. Indie/folk acts Cat Power and Iron &amp; Wine are based in the city, while alternative hip hop artist Sage Francis, electro artist Uffie, and the electroclash duo Avenue D were born in Miami, but musically based elsewhere. Also, ska punk band Against All Authority is from Miami, and rock/metal bands Nonpoint and Marilyn Manson each formed in neighboring Fort Lauderdale. Cuban American female recording artist, Ana Cristina, was born in Miami in 1985.</td>\n",
              "      <td>Along with Cat Power, what indie/folk musician is based in Miami?</td>\n",
              "      <td>{'text': ['Iron &amp; Wine'], 'answer_start': [303]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57102369a58dae1900cd68fa</td>\n",
              "      <td>Capital_punishment_in_the_United_States</td>\n",
              "      <td>Opponents argue that the death penalty is not an effective means of deterring crime, risks the execution of the innocent, is unnecessarily barbaric in nature, cheapens human life, and puts a government on the same base moral level as those criminals involved in murder. Furthermore, some opponents argue that the arbitrariness with which it is administered and the systemic influence of racial, socio-economic, geographic, and gender bias on determinations of desert make the current practice of capital punishment immoral and illegitimate.</td>\n",
              "      <td>Who do death penalty opponents believe may sometimes be executed?</td>\n",
              "      <td>{'text': ['the innocent'], 'answer_start': [108]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>572fc4abb2c2fd1400568425</td>\n",
              "      <td>Armenia</td>\n",
              "      <td>Armenia is also a member of the Council of Europe, maintaining friendly relations with the European Union, especially with its member states such as France and Greece. A 2005 survey reported that 64% of Armenia's population would be in favor of joining the EU. Several Armenian officials have also expressed the desire for their country to eventually become an EU member state, some[who?] predicting that it will make an official bid for membership in a few years.[citation needed] In 2004 its forces joined KFOR, a NATO-led international force in Kosovo. It is also an observer member of the Eurasian Economic Community and the Non-Aligned Movement.</td>\n",
              "      <td>How many of Armenias inhabitants approve of becoming part of the EU?</td>\n",
              "      <td>{'text': ['64%'], 'answer_start': [196]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57103337b654c5140001f8aa</td>\n",
              "      <td>Sexual_orientation</td>\n",
              "      <td>In the paper \"Who's Gay? Does It Matter?\", Ritch Savin-Williams proposes two different approaches to assessing sexual orientation until well positioned and psychometrically sound and tested definitions are developed that would allow research to reliably identify the prevalence, causes, and consequences of homosexuality. He first suggests that greater priority should be given to sexual arousal and attraction over behaviour and identity because it is less prone to self- and other-deception, social conditions and variable meanings. To measure attraction and arousal he proposed that biological measures should be developed and used. There are numerous biological/physiological measures that exist that can measure sexual orientation such as sexual arousal, brain scans, eye tracking, body odour preference, and anatomical variations such as digit-length ratio and right or left handedness. Secondly, Savin-Williams suggests that researchers should forsake the general notion of sexual orientation altogether and assess only those components that are relevant for the research question being investigated. For example:</td>\n",
              "      <td>What else does Savin-Williams suggest?</td>\n",
              "      <td>{'text': ['researchers should forsake the general notion of sexual orientation altogether'], 'answer_start': [932]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5724eebf0a492a1900435678</td>\n",
              "      <td>Freemasonry</td>\n",
              "      <td>In contrast to Catholic allegations of rationalism and naturalism, Protestant objections are more likely to be based on allegations of mysticism, occultism, and even Satanism. Masonic scholar Albert Pike is often quoted (in some cases misquoted) by Protestant anti-Masons as an authority for the position of Masonry on these issues. However, Pike, although undoubtedly learned, was not a spokesman for Freemasonry and was also controversial among Freemasons in general. His writings represented his personal opinion only, and furthermore an opinion grounded in the attitudes and understandings of late 19th century Southern Freemasonry of the USA. Notably, his book carries in the preface a form of disclaimer from his own Grand Lodge. No one voice has ever spoken for the whole of Freemasonry.</td>\n",
              "      <td>What are some Protestant objections to Freemasonry?</td>\n",
              "      <td>{'text': ['mysticism, occultism, and even Satanism'], 'answer_start': [135]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>56e16abbe3433e1400422ee1</td>\n",
              "      <td>Universal_Studios</td>\n",
              "      <td>Universal's multi-year film financing deal with Elliott Management expired in 2013. In July 2013, Universal made an agreement with Legendary Pictures to market, co-finance, and distribute Legendary's films for five years starting in 2014, the year that Legendary's similar agreement with Warner Bros. expires.</td>\n",
              "      <td>With whom did Universal sign a marketing and distribution deal in July 2013?</td>\n",
              "      <td>{'text': ['Legendary Pictures'], 'answer_start': [131]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>573368994776f41900660a3f</td>\n",
              "      <td>Financial_crisis_of_2007%E2%80%9308</td>\n",
              "      <td>IndyMac often made loans without verification of the borrower’s income or assets, and to borrowers with poor credit histories. Appraisals obtained by IndyMac on underlying collateral were often questionable as well. As an Alt-A lender, IndyMac’s business model was to offer loan products to fit the borrower’s needs, using an extensive array of risky option-adjustable-rate-mortgages (option ARMs), subprime loans, 80/20 loans, and other nontraditional products. Ultimately, loans were made to many borrowers who simply could not afford to make their payments. The thrift remained profitable only as long as it was able to sell those loans in the secondary mortgage market. IndyMac resisted efforts to regulate its involvement in those loans or tighten their issuing criteria: see the comment by Ruthann Melbourne, Chief Risk Officer, to the regulating agencies.</td>\n",
              "      <td>IndyMac often made loans without verifying what?</td>\n",
              "      <td>{'text': ['the borrower’s income'], 'answer_start': [49]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>572f3d1f04bcaa1900d767b1</td>\n",
              "      <td>Modern_history</td>\n",
              "      <td>Around the end of the 19th century and into the 20th century, the Meiji era was marked by the reign of the Meiji Emperor. During this time, Japan started its modernization and rose to world power status. This era name means \"Enlightened Rule\". In Japan, the Meiji Restoration started in the 1860s, marking the rapid modernization by the Japanese themselves along European lines. Much research has focused on the issues of discontinuity versus continuity with the previous Tokugawa Period. In the 1960s younger Japanese scholars led by Irokawa Daikichi, reacted against the bureaucratic superstate, and began searching for the historic role of the common people . They avoided the elite, and focused not on political events but on social forces and attitudes. They rejected both Marxism and modernization theory as alien and confining. They stressed the importance of popular energies in the development of modern Japan. They enlarged history by using the methods of social history. It was not until the beginning of the Meiji Era that the Japanese government began taking modernization seriously. Japan expanded its military production base by opening arsenals in various locations. The hyobusho (war office) was replaced with a War Department and a Naval Department. The samurai class suffered great disappointment the following years.</td>\n",
              "      <td>What was the Meija era marked by?</td>\n",
              "      <td>{'text': ['the reign of the Meiji Emperor'], 'answer_start': [90]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>56df5da88bc80c19004e4b26</td>\n",
              "      <td>Oklahoma_City</td>\n",
              "      <td>On April 19, 1995, the Alfred P. Murrah Federal Building was destroyed by a fertilizer bomb manufactured and detonated by Timothy McVeigh. The blast and catastrophic collapse killed 168 people and injured over 680. The blast shockwave destroyed or damaged 324 buildings within a 340-meter radius, destroyed or burned 86 cars, and shattered glass in 258 nearby buildings, causing at least an estimated $652 million worth of damage. The main suspect- Timothy McVeigh, was executed by lethal injection on June 11, 2001. It was the deadliest single domestic terrorist attack in US history, prior to 9/11.</td>\n",
              "      <td>How many people were killed in the bombing?</td>\n",
              "      <td>{'text': ['168'], 'answer_start': [182]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>57293d9e1d046914007791cf</td>\n",
              "      <td>New_Haven,_Connecticut</td>\n",
              "      <td>New Haven (local /nuː ˈheɪvən/, noo-HAY-vən), in the U.S. state of Connecticut, is the principal municipality in Greater New Haven, which had a total population of 862,477 in 2010. It is located on New Haven Harbor on the northern shore of the Long Island Sound in New Haven County, Connecticut, which in turn comprises the outer limits of the New York metropolitan area. It is the second-largest city in Connecticut (after Bridgeport), with a population of 129,779 people as of the 2010 United States Census. According to a census of 1 July 2012, by the Census Bureau, the city had a population of 130,741.</td>\n",
              "      <td>What is the metropolitan next to New Haven County, Connecticut?</td>\n",
              "      <td>{'text': ['New York'], 'answer_start': [344]}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##数据处理\n"
      ],
      "metadata": {
        "id": "S-TWDqZnJiXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
        "pad_on_right = tokenizer.padding_side == \"right\"\n",
        "\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
        "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
        "    # left whitespace\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e74cfe8889c048cb998c2779a4b19a4a",
            "941601b03459471abebd1774e31adab7",
            "02aa9c296c834525942a68c7137e2720",
            "7c9961538b0d4c4d9e6d63cb3171891d",
            "b9a140e440db495889d883d2375d7ea9",
            "370678d5bc464f089738c19adc8383b5",
            "d8fecbd0b1964050bb60a660ac6cabde",
            "3dd497005ea541599b1b99e355c70f81",
            "ddf68994cd9c4e11b4e1ad62138842f1",
            "2e73162cbe6c4f079ccb18955d81d62a",
            "789df237fba64096885fa87b6f38b1c4",
            "6a14faa044824a00b2486cef01995c71",
            "06e8ef7825db4a699428555df67f97d0",
            "bdc45207350945b39e319c23066222c8",
            "fca50d376a194e9d96e37a7ec07911bb",
            "a92f30c853e24c9db920d9d2d8e160f2",
            "cbc8fb17789c4b839cc29494b0eb0881",
            "b412cd1c43694f2db5a47f3b2b453b93",
            "6367cbe64f2642b7993b03d408f47678",
            "20e86cfa162a4cbf8e768fd8167a078b",
            "879130c176664f798981030916edf4fc",
            "1498fb2c370141619d84b06bea0c4129"
          ]
        },
        "id": "FXc2LketJlxE",
        "outputId": "7dca5373-d577-459f-e443-70e82c884889"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/88 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e74cfe8889c048cb998c2779a4b19a4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a14faa044824a00b2486cef01995c71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##加载模型，并进行fine-tune\n"
      ],
      "metadata": {
        "id": "BOmuc7ieL67X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers import default_data_collator,TrainingArguments,Trainer\n",
        "\n",
        "data_collator = default_data_collator\n",
        "\n",
        "model=AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-squad\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.save_model('test-squal-trained')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JKqgbIHGMA3Z",
        "outputId": "ecdc23ff-53cd-4bce-95dc-002df7594ea8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 88524\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 16599\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16599' max='16599' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16599/16599 2:48:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.224900</td>\n",
              "      <td>1.166393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>1.118430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.769000</td>\n",
              "      <td>1.158267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-1000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-1000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-1500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-1500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-2000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-2000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-2500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-2500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-3000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-3000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-3000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-3500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-3500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-4000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-4000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-4000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-4500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-4500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-4500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-5000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-5000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-5000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-5500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-5500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-5500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10784\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-6000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-6000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-6000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-6500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-6500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-6500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-7000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-7000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-7000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-7500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-7500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-7500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-8000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-8000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-8000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-8500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-8500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-8500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-9000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-9000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-9000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-9500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-9500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-9500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-10000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-10000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-10000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-10500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-10500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-10500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-11000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-11000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-11000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10784\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-11500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-11500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-11500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-12000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-12000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-12000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-12500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-12500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-12500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-13000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-13000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-13000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-13500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-13500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-13500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-14000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-14000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-14000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-14500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-14500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-14500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-15000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-15000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-15000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-15500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-15500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-15500/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-16000\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-16000/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-16000/special_tokens_map.json\n",
            "Saving model checkpoint to distilbert-base-uncased-finetuned-squad/checkpoint-16500\n",
            "Configuration saved in distilbert-base-uncased-finetuned-squad/checkpoint-16500/config.json\n",
            "Model weights saved in distilbert-base-uncased-finetuned-squad/checkpoint-16500/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-base-uncased-finetuned-squad/checkpoint-16500/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-base-uncased-finetuned-squad/checkpoint-16500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10784\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to test-squal-trained\n",
            "Configuration saved in test-squal-trained/config.json\n",
            "Model weights saved in test-squal-trained/pytorch_model.bin\n",
            "tokenizer config file saved in test-squal-trained/tokenizer_config.json\n",
            "Special tokens file saved in test-squal-trained/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##评估模型"
      ],
      "metadata": {
        "id": "kxuKfeTXMdCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#查看模型输出\n",
        "import torch\n",
        "\n",
        "for batch in trainer.get_eval_dataloader():\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = trainer.model(**batch)\n",
        "output.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32wIpNCoMb1Q",
        "outputId": "e4396b65-ce56-489b-eea9-ca4506f138cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'start_logits', 'end_logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMA5ru3DM3bc",
        "outputId": "e096229d-7def-4aa8-faed-e4d79a7c207b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 46,  57,  78,  43, 118, 107,  72,  35, 107,  34,  73,  41,  80,  86,\n",
              "         156,  35], device='cuda:0'),\n",
              " tensor([ 47,  58,  81,  44, 118, 110,  75,  37, 110,  36,  76,  42,  83,  94,\n",
              "         158,  35], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_best_size = 20\n",
        "\n"
      ],
      "metadata": {
        "id": "hNeUF_-KNB9E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TwQLh2xjJF50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "cabec635c33e4392b448fcf3dd39c9a3",
            "52be18c9efa04d4582fc3d316bc9a231",
            "cae397f4ff214cb9aa7ce1909023fbca",
            "c9817373e6bc49298ca5eb2afccbb921",
            "e42f49487a42481b9e964d5c894d6975",
            "a0e93ad4f5cb49a3959503dced9b0bd3",
            "c3429c05b1734841b1fba76f32fa1706",
            "818c8ff6e22c4f9489bcd8020bbf55e7",
            "f0d432944b3e40728af5cd01ecd4dcff",
            "8588bbff508c41c09926ebf0cfd6ce2f",
            "8f3fafd0dee74a76a82a4d59dcabbd22"
          ]
        },
        "outputId": "a568e96a-64b5-4bc2-fa6f-b96685b68176"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cabec635c33e4392b448fcf3dd39c9a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 10784\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='674' max='674' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [674/674 02:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
        "                }\n",
        "            )\n",
        "\n",
        "def prepare_validation_features(examples):\n",
        "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
        "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
        "    # left whitespace\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "validation_features = datasets[\"validation\"].map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets[\"validation\"].column_names\n",
        ")\n",
        "\n",
        "raw_predictions = trainer.predict(validation_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n",
        "\n",
        "max_answer_length = 30\n",
        "\n",
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
        "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
        "# an example index\n",
        "context = datasets[\"validation\"][0][\"context\"]\n",
        "\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "        # to part of the input_ids that are not in the context.\n",
        "        if (\n",
        "            start_index >= len(offset_mapping)\n",
        "            or end_index >= len(offset_mapping)\n",
        "            or offset_mapping[start_index] is None\n",
        "            or offset_mapping[end_index] is None\n",
        "        ):\n",
        "            continue\n",
        "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "            continue\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            start_char = offset_mapping[start_index][0]\n",
        "            end_char = offset_mapping[end_index][1]\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": context[start_char: end_char]\n",
        "                }\n",
        "            )\n",
        "\n",
        "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "valid_answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zlC6jMzNR1J",
        "outputId": "5571ddd9-05ac-4f1b-fd1e-2822f545ae12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 16.71362, 'text': 'Denver Broncos'},\n",
              " {'score': 14.335124,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
              " {'score': 12.5681, 'text': 'Broncos'},\n",
              " {'score': 12.50442, 'text': 'Carolina Panthers'},\n",
              " {'score': 11.400232, 'text': 'Denver'},\n",
              " {'score': 10.732788,\n",
              "  'text': 'The American Football Conference (AFC) champion Denver Broncos'},\n",
              " {'score': 10.189604,\n",
              "  'text': 'Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
              " {'score': 9.437442,\n",
              "  'text': 'American Football Conference (AFC) champion Denver Broncos'},\n",
              " {'score': 8.554966,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina'},\n",
              " {'score': 8.354293,\n",
              "  'text': 'The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
              " {'score': 8.194734,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10'},\n",
              " {'score': 7.158816,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference (NFC)'},\n",
              " {'score': 7.151225, 'text': 'Panthers'},\n",
              " {'score': 7.0589466,\n",
              "  'text': 'American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers'},\n",
              " {'score': 6.7279167,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference (NFC'},\n",
              " {'score': 6.724262, 'text': 'Carolina'},\n",
              " {'score': 6.550577, 'text': 'AFC) champion Denver Broncos'},\n",
              " {'score': 6.3640294, 'text': 'Carolina Panthers 24–10'},\n",
              " {'score': 6.3132963,\n",
              "  'text': 'Denver Broncos defeated the National Football Conference'},\n",
              " {'score': 5.5001035, 'text': 'champion Denver Broncos'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[\"validation\"][0][\"answers\"]\n",
        "\n",
        "import collections\n",
        "\n",
        "examples = datasets[\"validation\"]\n",
        "features = validation_features\n",
        "\n",
        "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "features_per_example = collections.defaultdict(list)\n",
        "for i, feature in enumerate(features):\n",
        "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "        \n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        else:\n",
        "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
        "            predictions[example[\"id\"]] = answer\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)\n",
        "\n",
        "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
        "\n",
        "if squad_v2:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "else:\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
        "metric.compute(predictions=formatted_predictions, references=references)"
      ],
      "metadata": {
        "id": "cWdt0KmJNZBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}